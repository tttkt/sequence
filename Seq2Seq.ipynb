{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = 71\n",
    "num_decoder_tokens = 93\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models(n_input, n_output, n_units):\n",
    "    #define training encoder\n",
    "    encoder_inputs = Input(shape=(None, n_input))\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, n_output))\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_output, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # define encoder inference model\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    # define decoder inference model\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n",
    "    # encode\n",
    "    state = infenc.predict(source)\n",
    "    # start of sequence input\n",
    "    target_seq = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE=50000\n",
    "DIGITS=3\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "seen = set()\n",
    "questions = []\n",
    "expected = []\n",
    "REVERSE = True\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n"
     ]
    }
   ],
   "source": [
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789')) \n",
    "                            for _ in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    key = tuple(sorted((a, b)))    \n",
    "\n",
    "    #if key in seen:\n",
    "        #continue\n",
    "    seen.add(key)\n",
    "\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        query = query[::-1]\n",
    "\n",
    "    questions.append(query)\n",
    "    expected.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "#자리를 만들고\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 7, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#섞기\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "#트레이닝과 테스트 셋 나누기\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7, 12)\n",
      "(5000, 7, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [ True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [ True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [ True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 4, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, RepeatVector, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                19712     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 32)             12416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4, 12)             396       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 32,524\n",
      "Trainable params: 32,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "45000/45000 [==============================] - 11s 237us/step - loss: 1.6052 - acc: 0.4368 - val_loss: 1.4771 - val_acc: 0.4591\n",
      "Epoch 2/50\n",
      "45000/45000 [==============================] - 8s 182us/step - loss: 1.4401 - acc: 0.4759 - val_loss: 1.3902 - val_acc: 0.4945\n",
      "Epoch 3/50\n",
      "45000/45000 [==============================] - 9s 197us/step - loss: 1.3512 - acc: 0.5021 - val_loss: 1.2982 - val_acc: 0.5237\n",
      "Epoch 4/50\n",
      "45000/45000 [==============================] - 8s 175us/step - loss: 1.2054 - acc: 0.5519 - val_loss: 1.1027 - val_acc: 0.5857\n",
      "Epoch 5/50\n",
      "45000/45000 [==============================] - 9s 195us/step - loss: 1.0526 - acc: 0.6035 - val_loss: 0.9903 - val_acc: 0.6330\n",
      "Epoch 6/50\n",
      "45000/45000 [==============================] - 9s 193us/step - loss: 0.9445 - acc: 0.6511 - val_loss: 0.8903 - val_acc: 0.6692\n",
      "Epoch 7/50\n",
      "45000/45000 [==============================] - 9s 197us/step - loss: 0.8544 - acc: 0.6890 - val_loss: 0.8079 - val_acc: 0.7096\n",
      "Epoch 8/50\n",
      "45000/45000 [==============================] - 8s 184us/step - loss: 0.7784 - acc: 0.7200 - val_loss: 0.7514 - val_acc: 0.7288\n",
      "Epoch 9/50\n",
      "45000/45000 [==============================] - 8s 181us/step - loss: 0.7144 - acc: 0.7440 - val_loss: 0.6915 - val_acc: 0.7546\n",
      "Epoch 10/50\n",
      "45000/45000 [==============================] - 8s 182us/step - loss: 0.6576 - acc: 0.7652 - val_loss: 0.6342 - val_acc: 0.7714\n",
      "Epoch 11/50\n",
      "45000/45000 [==============================] - 8s 176us/step - loss: 0.6088 - acc: 0.7826 - val_loss: 0.5956 - val_acc: 0.7850\n",
      "Epoch 12/50\n",
      "45000/45000 [==============================] - 8s 186us/step - loss: 0.5644 - acc: 0.7987 - val_loss: 0.5469 - val_acc: 0.8057\n",
      "Epoch 13/50\n",
      "45000/45000 [==============================] - 8s 178us/step - loss: 0.5241 - acc: 0.8126 - val_loss: 0.5063 - val_acc: 0.8201\n",
      "Epoch 14/50\n",
      "45000/45000 [==============================] - 8s 178us/step - loss: 0.4858 - acc: 0.8274 - val_loss: 0.4746 - val_acc: 0.8295\n",
      "Epoch 15/50\n",
      "45000/45000 [==============================] - 8s 176us/step - loss: 0.4490 - acc: 0.8414 - val_loss: 0.4409 - val_acc: 0.8400\n",
      "Epoch 16/50\n",
      "45000/45000 [==============================] - 8s 180us/step - loss: 0.4152 - acc: 0.8534 - val_loss: 0.4123 - val_acc: 0.8518\n",
      "Epoch 17/50\n",
      "45000/45000 [==============================] - 9s 198us/step - loss: 0.3840 - acc: 0.8643 - val_loss: 0.3884 - val_acc: 0.8605\n",
      "Epoch 18/50\n",
      "45000/45000 [==============================] - 8s 182us/step - loss: 0.3510 - acc: 0.8781 - val_loss: 0.3480 - val_acc: 0.8752\n",
      "Epoch 19/50\n",
      "45000/45000 [==============================] - 8s 172us/step - loss: 0.3217 - acc: 0.8890 - val_loss: 0.3190 - val_acc: 0.8894\n",
      "Epoch 20/50\n",
      "45000/45000 [==============================] - 8s 188us/step - loss: 0.2932 - acc: 0.9002 - val_loss: 0.2958 - val_acc: 0.8972\n",
      "Epoch 21/50\n",
      "45000/45000 [==============================] - 9s 194us/step - loss: 0.2683 - acc: 0.9101 - val_loss: 0.2618 - val_acc: 0.9117\n",
      "Epoch 22/50\n",
      "45000/45000 [==============================] - 8s 174us/step - loss: 0.2432 - acc: 0.9204 - val_loss: 0.2382 - val_acc: 0.9215\n",
      "Epoch 23/50\n",
      "45000/45000 [==============================] - 11s 236us/step - loss: 0.2224 - acc: 0.9282 - val_loss: 0.2250 - val_acc: 0.9245\n",
      "Epoch 24/50\n",
      "45000/45000 [==============================] - 9s 191us/step - loss: 0.2022 - acc: 0.9359 - val_loss: 0.2105 - val_acc: 0.9294\n",
      "Epoch 25/50\n",
      "45000/45000 [==============================] - 8s 169us/step - loss: 0.1855 - acc: 0.9421 - val_loss: 0.1877 - val_acc: 0.9397\n",
      "Epoch 26/50\n",
      "45000/45000 [==============================] - 8s 172us/step - loss: 0.1697 - acc: 0.9479 - val_loss: 0.1796 - val_acc: 0.9421\n",
      "Epoch 27/50\n",
      "45000/45000 [==============================] - 8s 167us/step - loss: 0.1553 - acc: 0.9529 - val_loss: 0.1623 - val_acc: 0.9477\n",
      "Epoch 28/50\n",
      "45000/45000 [==============================] - 8s 178us/step - loss: 0.1431 - acc: 0.9577 - val_loss: 0.1522 - val_acc: 0.9506\n",
      "Epoch 29/50\n",
      "45000/45000 [==============================] - 8s 176us/step - loss: 0.1330 - acc: 0.9606 - val_loss: 0.1386 - val_acc: 0.9562\n",
      "Epoch 30/50\n",
      "45000/45000 [==============================] - 8s 167us/step - loss: 0.1230 - acc: 0.9642 - val_loss: 0.1262 - val_acc: 0.9613\n",
      "Epoch 31/50\n",
      "45000/45000 [==============================] - 8s 173us/step - loss: 0.1104 - acc: 0.9683 - val_loss: 0.1187 - val_acc: 0.9637\n",
      "Epoch 32/50\n",
      "45000/45000 [==============================] - 8s 180us/step - loss: 0.1026 - acc: 0.9714 - val_loss: 0.1164 - val_acc: 0.9643\n",
      "Epoch 33/50\n",
      "45000/45000 [==============================] - 8s 167us/step - loss: 0.0951 - acc: 0.9734 - val_loss: 0.1052 - val_acc: 0.9681\n",
      "Epoch 34/50\n",
      "45000/45000 [==============================] - 8s 177us/step - loss: 0.0886 - acc: 0.9754 - val_loss: 0.0990 - val_acc: 0.9702\n",
      "Epoch 35/50\n",
      "45000/45000 [==============================] - 9s 205us/step - loss: 0.0851 - acc: 0.9766 - val_loss: 0.0902 - val_acc: 0.9715\n",
      "Epoch 36/50\n",
      "45000/45000 [==============================] - 8s 182us/step - loss: 0.0731 - acc: 0.9808 - val_loss: 0.0866 - val_acc: 0.9722\n",
      "Epoch 37/50\n",
      "45000/45000 [==============================] - 8s 182us/step - loss: 0.0722 - acc: 0.9807 - val_loss: 0.0834 - val_acc: 0.9738\n",
      "Epoch 38/50\n",
      "45000/45000 [==============================] - 8s 175us/step - loss: 0.0646 - acc: 0.9835 - val_loss: 0.1152 - val_acc: 0.9617\n",
      "Epoch 39/50\n",
      "45000/45000 [==============================] - 8s 172us/step - loss: 0.0610 - acc: 0.9843 - val_loss: 0.0728 - val_acc: 0.9778\n",
      "Epoch 40/50\n",
      "45000/45000 [==============================] - 7s 164us/step - loss: 0.0550 - acc: 0.9865 - val_loss: 0.0709 - val_acc: 0.9786\n",
      "Epoch 41/50\n",
      "45000/45000 [==============================] - 7s 161us/step - loss: 0.0570 - acc: 0.9849 - val_loss: 0.0911 - val_acc: 0.9707\n",
      "Epoch 42/50\n",
      "45000/45000 [==============================] - 7s 158us/step - loss: 0.0494 - acc: 0.9880 - val_loss: 0.0603 - val_acc: 0.9821\n",
      "Epoch 43/50\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 0.0454 - acc: 0.9887 - val_loss: 0.0566 - val_acc: 0.9829\n",
      "Epoch 44/50\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 0.0419 - acc: 0.9900 - val_loss: 0.0730 - val_acc: 0.9779\n",
      "Epoch 45/50\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 0.0487 - acc: 0.9870 - val_loss: 0.0754 - val_acc: 0.9763\n",
      "Epoch 46/50\n",
      "45000/45000 [==============================] - 7s 159us/step - loss: 0.0377 - acc: 0.9912 - val_loss: 0.0580 - val_acc: 0.9819\n",
      "Epoch 47/50\n",
      "45000/45000 [==============================] - 7s 162us/step - loss: 0.0358 - acc: 0.9916 - val_loss: 0.0610 - val_acc: 0.9820\n",
      "Epoch 48/50\n",
      "45000/45000 [==============================] - 7s 159us/step - loss: 0.0340 - acc: 0.9923 - val_loss: 0.0463 - val_acc: 0.9860\n",
      "Epoch 49/50\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 0.0339 - acc: 0.9915 - val_loss: 0.0556 - val_acc: 0.9833\n",
      "Epoch 50/50\n",
      "45000/45000 [==============================] - 7s 160us/step - loss: 0.0308 - acc: 0.9928 - val_loss: 0.0543 - val_acc: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1227f16d8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "#encode\n",
    "model.add(LSTM(64, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(RepeatVector(DIGITS + 1))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "    \n",
    "    \n",
    "for i in range(10):\n",
    "    ind = np.random.randint(0, len(x_val))\n",
    "    rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "    preds = model.predict_classes(rowx)\n",
    "    q = ctable.decode(rowx[0])\n",
    "    correct = ctable.decode(rowy[0])\n",
    "    guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "    print('%5d' % ind, end=': ')\n",
    "    print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "    print('T', correct, end=' ')\n",
    "    if correct == guess:\n",
    "        print(colors.ok + '☑' + colors.close, end=' ')\n",
    "    else:\n",
    "        print(colors.fail + '☒' + colors.close, end=' ')\n",
    "    print(guess)\n",
    "\n",
    "# %% Print final results.\n",
    "\n",
    "i = 2975\n",
    "output_final = model.predict(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[3].output)\n",
    "output = intermediate_layer_model.predict(x_val)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[i].output)\n",
    "    output = intermediate_layer_model.predict(x_val)\n",
    "    plt.clf() #그래프 초기화\n",
    "    sns.heatmap(output[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_val, y_val, verbose=1)\n",
    "print('-loss:',loss, '\\n-accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_val, y_val, verbose=1)\n",
    "print('-loss:',loss, '\\n-accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
